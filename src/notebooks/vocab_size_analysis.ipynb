{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotnine as pn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sciterra import Atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default Word2Vec parameters, we get a vocabulary of roughly 17,000 words. This is intuitively too large for our dataset of 30k abstracts (rougly 3M words), so we should explore how to make this vocab smaller. However, the original Word2Vec paper evaluated on datasets of orders of magnitude larger than ours, so perhaps this is not a problem for word2vec, but just for BOW.\n",
    "\n",
    "Specifically, they have a ratio of using only most frequent 30k words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_dirs_w2v = {\n",
    "    \"Physics\": \"/Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=hafenLowredshiftLymanLimit2017\",\n",
    "\n",
    "    \"Linguistics\": \"/Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=Imeletal2022\",\n",
    "\n",
    "    \"Medicine\": \"/Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=Torres2013\",\n",
    "\n",
    "    \"Education\": \"/Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=Ololube2012\",\n",
    "\n",
    "    \"Philosophy\": \"/Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=Bacon2019\",\n",
    "\n",
    "    \"Economics\": \"/Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=West2003\",\n",
    "\n",
    "    \"Materials Science\": \"/Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=Miele2022\",\n",
    "\n",
    "    \"Geology\": \"/Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=ForeroOrtega2021\",\n",
    "\n",
    "    \"Mathematics\": \"/Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=Andre2018\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might be memory intensive.\n",
    "\n",
    "atlases_by_field: dict[str, Atlas] = {\n",
    "    key: Atlas.load(atlas_dirs_w2v[key]) for key in atlas_dirs_w2v\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sciterra.vectorization import Word2VecVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved Word2Vec model from /Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=hafenLowredshiftLymanLimit2017/w2v.model.\n",
      "Saving Word2Vec model at /Users/nathanielimel/uci/projects/citesim/outputs/librarian=S2/vectorizer=Word2Vec/center=hafenLowredshiftLymanLimit2017/w2v.model.\n"
     ]
    }
   ],
   "source": [
    "field = \"Physics\"\n",
    "model_path = os.path.join(atlas_dirs_w2v[field], \"w2v.model\")\n",
    "\n",
    "vectorizer = Word2VecVectorizer(\n",
    "    corpus_path=None,\n",
    "    model_path=model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39742"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect\n",
    "vectorizer.model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.model.max_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16975"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3626685"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.model.corpus_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004680582956611892"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.model.wv) / vectorizer.model.corpus_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do we get the frequencies?\n",
    "vectorizer.model.effective_min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([113302,  45570,  38499, ...,      2,      2,      2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_obj = w2v.vocab[\"word\"]\n",
    "# vocab_obj.count\n",
    "\n",
    "vectorizer.model.wv.sort_by_descending_frequency()\n",
    "vectorizer.model.wv.key_to_index # INDICES, not counts!\n",
    "vectorizer.model.wv.expandos['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we reduce vocab using min count 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['count', 'sample_int'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.model.wv.expandos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([113302,  45570,  38499, ...,      4,      4,      4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first 10,000 include words of freq 4\n",
    "vectorizer.model.wv.expandos['count'][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([113302,  45570,  38499,  29350,  29328,  28699,  28348,  28313,\n",
       "        28241,  28071,  27628,  27062,  25481,  23306,  23041,  20018,\n",
       "        19986,  18933,  18766,  18242,  17959,  17426,  17332,  16945,\n",
       "        16403,  16248,  15165,  14817,  14673,  14607,  14601,  14239,\n",
       "        14219,  13417,  12551,  12501,  12371,  12341,  12104,  11901,\n",
       "        11620,  11510,  11474,  11294,  11119,  11040,  10986,  10839,\n",
       "        10824,  10750,  10534,  10418,  10396,  10307,  10187,  10094,\n",
       "        10016,   9988,   9942,   9926,   9637,   9345,   9177,   9097,\n",
       "         9070,   8688,   8616,   8610,   8393,   8305,   8182,   8135,\n",
       "         8020,   7944,   7932,   7882,   7821,   7807,   7795,   7641,\n",
       "         7540,   7411,   7381,   7362,   7357,   7310,   7309,   7278,\n",
       "         7253,   7245,   7192,   7189,   7143,   7065,   7064,   6907,\n",
       "         6904,   6894,   6862,   6834,   6819,   6714,   6712,   6687,\n",
       "         6517,   6475,   6474,   6435,   6307,   6298,   6285,   6262,\n",
       "         6238,   6237,   6165,   6160,   6120,   6104,   6097,   6064,\n",
       "         5977,   5968,   5913,   5899,   5878,   5852,   5829,   5805,\n",
       "         5642,   5586,   5513,   5470,   5469,   5448,   5419,   5417,\n",
       "         5388,   5241,   5201,   5198,   5181,   5175,   5106,   5056,\n",
       "         5007,   4946,   4934,   4893,   4889,   4816,   4784,   4762,\n",
       "         4732,   4718,   4695,   4694,   4638,   4605,   4592,   4566,\n",
       "         4555,   4530,   4503,   4499,   4440,   4436,   4427,   4387,\n",
       "         4345,   4299,   4287,   4285,   4250,   4225,   4218,   4184,\n",
       "         4145,   4143,   4142,   4135,   4086,   4050,   4024,   4008,\n",
       "         3995,   3969,   3965,   3964,   3959,   3948,   3933,   3849,\n",
       "         3846,   3827,   3810,   3804,   3800,   3786,   3766,   3737,\n",
       "         3729,   3719,   3697,   3695,   3686,   3685,   3676,   3619,\n",
       "         3576,   3535,   3530,   3518,   3468,   3449,   3437,   3436,\n",
       "         3434,   3429,   3392,   3387,   3385,   3379,   3377,   3372,\n",
       "         3360,   3353,   3347,   3344,   3339,   3323,   3309,   3308,\n",
       "         3306,   3295,   3285,   3283,   3281,   3280,   3239,   3235,\n",
       "         3225,   3174,   3170,   3168,   3162,   3156,   3154,   3130,\n",
       "         3108,   3100,   3092,   3086,   3081,   3079,   3078,   3072,\n",
       "         3068,   3060,   3057,   3043,   3041,   3035,   3017,   3001,\n",
       "         2989,   2974,   2967,   2952,   2942,   2911,   2908,   2901,\n",
       "         2900,   2900,   2881,   2881,   2878,   2863,   2860,   2851,\n",
       "         2848,   2847,   2845,   2837,   2831,   2809,   2803,   2802,\n",
       "         2795,   2791,   2791,   2768,   2763,   2761,   2750,   2747,\n",
       "         2740,   2734,   2732,   2730,   2716,   2707,   2707,   2687,\n",
       "         2686,   2684,   2682,   2677,   2671,   2664,   2650,   2633,\n",
       "         2629,   2626,   2625,   2624,   2622,   2619,   2612,   2596,\n",
       "         2570,   2558,   2552,   2510,   2500,   2479,   2473,   2465,\n",
       "         2458,   2457,   2452,   2439,   2431,   2406,   2401,   2393,\n",
       "         2393,   2391,   2363,   2357,   2356,   2347,   2322,   2319,\n",
       "         2314,   2312,   2299,   2296,   2284,   2283,   2281,   2276,\n",
       "         2275,   2270,   2265,   2257,   2247,   2242,   2239,   2228,\n",
       "         2210,   2200,   2197,   2184,   2181,   2168,   2140,   2129,\n",
       "         2124,   2117,   2115,   2112,   2095,   2087,   2086,   2086,\n",
       "         2083,   2078,   2077,   2074,   2061,   2058,   2058,   2055,\n",
       "         2032,   2031,   2030,   2022,   2016,   2016,   2004,   2002,\n",
       "         1980,   1978,   1976,   1973,   1972,   1970,   1969,   1966,\n",
       "         1955,   1953,   1947,   1941,   1932,   1930,   1923,   1920,\n",
       "         1907,   1906,   1900,   1899,   1897,   1892,   1887,   1887,\n",
       "         1887,   1886,   1885,   1871,   1867,   1867,   1850,   1845,\n",
       "         1843,   1837,   1833,   1819,   1814,   1812,   1807,   1805,\n",
       "         1799,   1793,   1787,   1779,   1778,   1777,   1775,   1775,\n",
       "         1768,   1766,   1755,   1754,   1752,   1744,   1735,   1735,\n",
       "         1723,   1721,   1716,   1713,   1709,   1697,   1697,   1692,\n",
       "         1691,   1683,   1681,   1681,   1679,   1673,   1667,   1655,\n",
       "         1652,   1650,   1649,   1648,   1648,   1646,   1645,   1641,\n",
       "         1638,   1632,   1632,   1628,   1626,   1617,   1613,   1609,\n",
       "         1605,   1605,   1604,   1601,   1599,   1595,   1585,   1585,\n",
       "         1580,   1579,   1574,   1563,   1557,   1554,   1553,   1552,\n",
       "         1549,   1548,   1542,   1541,   1540,   1538,   1537,   1536,\n",
       "         1535,   1528,   1515,   1514,   1514,   1513,   1509,   1508,\n",
       "         1506,   1500,   1493,   1493,   1490,   1489,   1477,   1476,\n",
       "         1475,   1473,   1469,   1467,   1463,   1463,   1461,   1458,\n",
       "         1455,   1453,   1452,   1451,   1450,   1450,   1443,   1443,\n",
       "         1437,   1434,   1433,   1427,   1425,   1417,   1408,   1408,\n",
       "         1407,   1400,   1395,   1388,   1379,   1376,   1369,   1359,\n",
       "         1357,   1350,   1342,   1340,   1340,   1339,   1335,   1333,\n",
       "         1331,   1331,   1330,   1325,   1325,   1318,   1315,   1309,\n",
       "         1301,   1298,   1296,   1294,   1287,   1285,   1279,   1278,\n",
       "         1277,   1270,   1268,   1260,   1256,   1255,   1252,   1251,\n",
       "         1249,   1246,   1245,   1244,   1243,   1242,   1240,   1239,\n",
       "         1236,   1230,   1229,   1228,   1228,   1228,   1227,   1219,\n",
       "         1218,   1218,   1216,   1215,   1214,   1214,   1214,   1211,\n",
       "         1209,   1209,   1205,   1201,   1200,   1197,   1197,   1197,\n",
       "         1196,   1190,   1189,   1185,   1183,   1182,   1181,   1181,\n",
       "         1179,   1172,   1170,   1163,   1163,   1158,   1158,   1157,\n",
       "         1157,   1156,   1154,   1151,   1147,   1145,   1142,   1138,\n",
       "         1136,   1133,   1127,   1126,   1123,   1121,   1121,   1119,\n",
       "         1114,   1113,   1113,   1106,   1101,   1099,   1093,   1088,\n",
       "         1087,   1082,   1080,   1077,   1075,   1075,   1073,   1071,\n",
       "         1059,   1056,   1055,   1045,   1044,   1043,   1037,   1035,\n",
       "         1034,   1027,   1023,   1022,   1021,   1021,   1019,   1018,\n",
       "         1016,   1015,   1013,   1011,   1009,   1009,   1008,   1007,\n",
       "         1004,   1001,    999,    997,    993,    989,    988,    978,\n",
       "          977,    975,    971,    971,    971,    969,    967,    966,\n",
       "          964,    961,    960,    960,    956,    956,    954,    949,\n",
       "          947,    944,    944,    943,    943,    941,    940,    940,\n",
       "          938,    937,    937,    936,    928,    928,    927,    923,\n",
       "          920,    919,    917,    916,    916,    916,    915,    915,\n",
       "          914,    913,    912,    912,    911,    908,    900,    894,\n",
       "          891,    891,    888,    888,    883,    882,    882,    881,\n",
       "          880,    879,    877,    873,    872,    872,    870,    870,\n",
       "          869,    865,    864,    860,    857,    855,    855,    855,\n",
       "          850,    847,    844,    843,    842,    841,    840,    834,\n",
       "          833,    827,    827,    826,    824,    823,    821,    820,\n",
       "          818,    817,    812,    809,    807,    806,    805,    805,\n",
       "          802,    800,    799,    798,    794,    794,    794,    791,\n",
       "          790,    789,    789,    789,    788,    784,    783,    782,\n",
       "          782,    782,    781,    777,    776,    773,    773,    771,\n",
       "          771,    770,    770,    768,    765,    764,    764,    764,\n",
       "          762,    762,    761,    759,    759,    758,    757,    757,\n",
       "          754,    749,    748,    747,    746,    746,    744,    744,\n",
       "          743,    742,    741,    740,    739,    739,    737,    735,\n",
       "          734,    734,    733,    731,    730,    730,    729,    728,\n",
       "          727,    723,    720,    719,    719,    716,    715,    713,\n",
       "          711,    710,    707,    706,    706,    706,    705,    705,\n",
       "          705,    704,    704,    700,    699,    698,    698,    685,\n",
       "          684,    682,    681,    680,    677,    669,    667,    665,\n",
       "          664,    664,    663,    662,    661,    661,    660,    659,\n",
       "          658,    658,    656,    655,    654,    653,    653,    653,\n",
       "          652,    651,    650,    649,    646,    645,    644,    642,\n",
       "          642,    641,    640,    640,    636,    636,    636,    635,\n",
       "          634,    632,    630,    628,    628,    627,    624,    623,\n",
       "          622,    621,    620,    619,    619,    618,    616,    615,\n",
       "          613,    611,    611,    610,    610,    608,    608,    606,\n",
       "          605,    604,    604,    602,    599,    599,    599,    599,\n",
       "          597,    597,    595,    595,    594,    591,    586,    585,\n",
       "          585,    585,    582,    581,    581,    581,    580,    579,\n",
       "          578,    578,    577,    577,    576,    576,    575,    572,\n",
       "          571,    570,    570,    570,    568,    567,    561,    560,\n",
       "          560,    559,    559,    558,    558,    557,    557,    555,\n",
       "          554,    551,    551,    551,    550,    550,    549,    549])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first 1000 include words of freq 549\n",
    "vectorizer.model.wv.expandos['count'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps, at least for Word2Vec, we should aim for a max vocab size of 10,000."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citesim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
